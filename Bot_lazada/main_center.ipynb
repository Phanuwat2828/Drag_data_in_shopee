{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time;\n",
    "from pynput import mouse\n",
    "import pyautogui\n",
    "from pynput import keyboard\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as b\n",
    "import pandas as pd\n",
    "from fnmatch import fnmatch\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install\n",
    "pip insatll bs4\n",
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Link_all\n",
    "def get_link(i):\n",
    "    url = ['https://www.lazada.co.th/?spm=a2o4m.searchlistcategory.breadcrumb.1.31f05424RLChei'];\n",
    "    lazada = 'https://'\n",
    "    path = '\\b?spm=a2o4m.home-th.3887232320.46.3a8d7f6dvzndMU'\n",
    "    data_link_all=[];\n",
    "    page = requests.get(url[i])\n",
    "    \n",
    "    soup = b(page.content,'html.parser')\n",
    "\n",
    "    all_link = soup.find_all('a');\n",
    "    j=0;\n",
    "    for link in all_link:\n",
    "        \n",
    "        href = link.get('href','')\n",
    "        # if (j>=22 and j<=1257 ):\n",
    "        if (j>=22 and j<=1282 ) and href:\n",
    "            # if(j!=126 and j!=127 and j!=128):\n",
    "                data = \"https://\"+href+path+\"&page=\";\n",
    "                data_link_all.append(data);\n",
    "        j+=1;\n",
    "    for i in range(3):\n",
    "         del data_link_all[126];\n",
    "    \n",
    "   \n",
    "    # print(all_link)\n",
    "    return(data_link_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in get_link(0):\n",
    "    print(i);\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Find_file_Donwload_after_change_name\n",
    "\n",
    "\n",
    "def find_files(directory, pattern):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if fnmatch(filename, pattern):\n",
    "                status = True  \n",
    "                yield os.path.join(root, filename)\n",
    "    \n",
    "            \n",
    "\n",
    "# ตัวอย่างการใช้งาน\n",
    "directory_to_search = r\"C:\\Drag_data_in_shopee\\Bot_lazada\\Data_lazada\"  # เปลี่ยนเป็นไดเรกทอรีที่คุณต้องการค้นหา\n",
    "file_pattern = \"lazada.xlsx\"  # เปลี่ยนเป็นรูปแบบไฟล์ที่คุณต้องการค้นหา (*.txt, *.pdf, เป็นต้น)\n",
    "\n",
    "def status():\n",
    "    status = False\n",
    "    for file_path in find_files(directory_to_search, file_pattern):\n",
    "        status = True;\n",
    "    print(status);\n",
    "    return status;\n",
    "status();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ดึงขนาดของหน้าจอ\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check_Header\n",
    "def check_data(path_file):\n",
    "       \n",
    "        header = ['col-xs-2-4 href', 'Fd4QmV src', 'FTxtVW',\n",
    "       'customized-overlay-image src', 'DgXDzJ', 'bPcAVl', 'k9JZlv',\n",
    "       'bx++ig 2', 'k9JZlv 2', 'OwmBnn', 'JVW3E2', 'hxLzax']\n",
    "       \n",
    "        df = pd.read_excel(path_file)\n",
    "       \n",
    "        is_subset = all(item in df.columns for item in header);\n",
    "        return is_subset;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Excell\n",
    "\n",
    "\n",
    "header = ['_95X4G href', 'jBwCF src', 'jBwCF src 2',\n",
    "       'RfADt', 'ooOxS', 'bPcAVl', 'k9JZlv',\n",
    "       'bx++ig 2', 'k9JZlv 2', 'OwmBnn', 'JVW3E2', 'hxLzax']\n",
    "header_Values = {\n",
    "    'col-xs-2-4 href':\"product\",\n",
    "    'Fd4QmV src':\"image_product_1\",\n",
    "    'FTxtVW':\"discount\",\n",
    "    'customized-overlay-image src':\"image_product_2\",\n",
    "    'DgXDzJ':\"data_product\", \n",
    "    'bPcAVl':\"price_before\",\n",
    "    'k9JZlv':\"price_product_1\",\n",
    "    'bx++ig 2':\"Emoji\",\n",
    "    'k9JZlv 2':\"price_product_2\",\n",
    "    'OwmBnn':\"sold\",\n",
    "    'JVW3E2':\"place\", \n",
    "    'hxLzax':\"Recommended_shops\"\n",
    "}\n",
    "def data_process(path_file):\n",
    "  \n",
    "        # path_file = './Data_shopee/Data_1_1_1.xlsx';\n",
    "        find = pd.read_excel(path_file);\n",
    "        data_all=[];\n",
    "        df = pd.read_excel(path_file)\n",
    "        num_rows, num_columns = df.shape\n",
    "        \n",
    "        \n",
    "        Data_everthing=[];\n",
    "        for i in range(num_rows):\n",
    "            data_process = {\n",
    "                \"product\":[],\n",
    "                \"price_product_2\":[],\n",
    "                \"price_product_1\":[],\n",
    "                \"image_product_1\":[],\n",
    "                \"discount\":[],\n",
    "                \"image_product_2\":[],\n",
    "                \"data_product\":[],\n",
    "                \"price_before\":[],\n",
    "                \"Emoji\":[],\n",
    "                \"sold\":[],\n",
    "                \"place\":[],\n",
    "                \"Recommended_shops\":[]\n",
    "            }\n",
    "            data = \"Product_\"+str(i+1);\n",
    "            Product = {\n",
    "                data:{\n",
    "                }\n",
    "            }\n",
    "            for j in range(12):\n",
    "                data_input = str(find[header[j]][i]);\n",
    "                data_process[header_Values[header[j]]]=data_input;\n",
    "                \n",
    "            Product[data]=data_process;\n",
    "            data_all.append(Product);\n",
    "            filename = \"Data_process.json\"\n",
    "            with open(filename, 'w', encoding='utf-8') as file:\n",
    "                json.dump(data_all, file, indent=2, ensure_ascii=False)\n",
    "           \n",
    "            test = len(Data_everthing);\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "screen_width, screen_height = pyautogui.size();\n",
    "width = 0;\n",
    "height = 0;\n",
    "if(screen_width!=1366):\n",
    "    width =screen_width-1366;\n",
    "if(screen_height!=768):\n",
    "    height = screen_height-768;\n",
    "Data = get_link(0);\n",
    "def custom_sleep(seconds):\n",
    "    time.sleep(seconds)\n",
    "def Scoll():\n",
    "    custom_sleep(2);\n",
    "    for i in range(7):\n",
    "        pyautogui.scroll(-750);\n",
    "        custom_sleep(6);\n",
    "    \n",
    "def click(x,y):\n",
    "    pyautogui.click(x-(width),y-(height));\n",
    "    custom_sleep(1.5);\n",
    "\n",
    "def type_and_enter(text):\n",
    "    controller = keyboard.Controller();\n",
    "    controller.type(text);\n",
    "    custom_sleep(2);\n",
    "    controller.press(keyboard.Key.enter);\n",
    "    controller.release(keyboard.Key.enter);\n",
    "\n",
    "def main(x):\n",
    "      # path\n",
    "    custom_sleep(3);\n",
    "    click(373, 62);\n",
    "    # input path\n",
    "    type_and_enter(x);\n",
    "    custom_sleep(4);\n",
    "    # Mouse clicked at (1360, 264) with Button.left\n",
    "    custom_sleep(2);\n",
    "    click(1257, 191);\n",
    "    Scoll();\n",
    "    # เลือกส่วนขยาย\n",
    "    click(1183, 61)\n",
    "    # ส่วนขยาย sracper\n",
    "    click(1012,236);\n",
    "    # download\n",
    "    # Mouse clicked at (834, 114) with Button.left\n",
    "    # Mouse clicked at (755, 179) with Button.left\n",
    "# Mouse clicked at (1006, 88) with Button.left\n",
    "    keyboard.press_and_release('F11')\n",
    "    custom_sleep(2);\n",
    "    click(760, 66);\n",
    "    # Mouse clicked at (1118, 17) with Button.left\n",
    "    custom_sleep(2);\n",
    "    keyboard.press_and_release('alt+F4')\n",
    "    # reface\n",
    "    custom_sleep(1);\n",
    "    keyboard.press_and_release('F5')\n",
    "def count_page(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    elements_a = driver.find_elements(By.CLASS_NAME,'b7FXJ');\n",
    "    result_list = []\n",
    "    for element in elements_a:\n",
    "        link = element.find_elements(By.TAG_NAME,'li');\n",
    "        for test in link:\n",
    "            result_list.append(test.text)\n",
    "    page = result_list[7];\n",
    "    driver.quit()\n",
    "    # พิมพ์ผลลัพธ์\n",
    "    return page;\n",
    "def check_data(path_file):\n",
    "       \n",
    "        header = ['col-xs-2-4 href', 'Fd4QmV src', 'FTxtVW',\n",
    "       'customized-overlay-image src', 'DgXDzJ', 'bPcAVl', 'k9JZlv',\n",
    "       'bx++ig 2', 'k9JZlv 2', 'OwmBnn', 'JVW3E2', 'hxLzax']\n",
    "       \n",
    "        df = pd.read_excel(path_file)\n",
    "       \n",
    "        is_subset = all(item in df.columns for item in header);\n",
    "        return is_subset;\n",
    "def change_name(i,j):\n",
    "    path ='.\\Data_lazada\\data'+'_'+str(i)+'_'+str(j)+'.xlsx'\n",
    "    path_file = 'C:\\Drag_data_in_shopee\\Bot_lazada\\Data_lazada\\lazada.xlsx';\n",
    "    new_file_name = 'data'+'_'+str(i)+'_'+str(j)+'.xlsx'\n",
    "    # สร้างเส้นทางสำหรับไฟล์ใหม่\n",
    "    new_file_path = os.path.join(os.path.dirname(path_file), new_file_name);\n",
    "    # เปลี่ยนชื่อไฟล์\n",
    "    shutil.move(path_file, new_file_path);\n",
    "    return path;\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        num2=0;\n",
    "        for i in range(len(Data)):\n",
    "            num2+=1;\n",
    "            num3=0;\n",
    "            \n",
    "            for j in range(int(count_page(Data[i]))):\n",
    "                data_sum=Data[i]+str(j);\n",
    "                main(data_sum);\n",
    "                find_shopee = status();\n",
    "                if(find_shopee==True):\n",
    "                    num3+=1;\n",
    "                    path = change_name(num2,num3);\n",
    "                    print(path);\n",
    "                    if(check_data(path)==True):\n",
    "                        data_process(path);\n",
    "                    else:\n",
    "                        destination_path = r\"C:\\Drag_data_in_shopee\\Bot_lazada\\Un_process\"  # เปลี่ยนเป็นเส้นทางจริงที่ต้องการย้ายไฟล์ไป\n",
    "                        shutil.move(path, destination_path)\n",
    "                        continue;\n",
    "                else:\n",
    "                    continue;\n",
    "                print(data_sum);\n",
    "            custom_sleep(120);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data_shopee/data_1_1_1.xlsx\n"
     ]
    }
   ],
   "source": [
    "# change_name\n",
    "def change_name(k,i,j):\n",
    "    path='./Data_shopee/data_'+str(k)+'_'+str(i)+'_'+str(j)+'.xlsx'\n",
    "    path_file = r'C:\\Drag_data_in_shopee\\Bot\\Data_shopee\\shopee.xlsx';\n",
    "    new_file_name = 'data_'+str(k)+'_'+str(i)+'_'+str(j)+'.xlsx'\n",
    "    # สร้างเส้นทางสำหรับไฟล์ใหม่\n",
    "    new_file_path = os.path.join(os.path.dirname(path_file), new_file_name)\n",
    "\n",
    "    # เปลี่ยนชื่อไฟล์\n",
    "    shutil.move(path_file, new_file_path)\n",
    "    return path;\n",
    "test = change_name(1,1,1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_process(path_file):\n",
    "        file = '/shopee.xlsx';\n",
    "        header = ['col-xs-2-4 href', 'Fd4QmV src', 'FTxtVW',\n",
    "       'customized-overlay-image src', 'DgXDzJ', 'bPcAVl', 'k9JZlv',\n",
    "       'bx++ig 2', 'k9JZlv 2', 'OwmBnn', 'JVW3E2', 'hxLzax']\n",
    "        find = pd.read_excel(path_file);\n",
    "        df = pd.read_excel(path_file)\n",
    "        status =0;\n",
    "        con =False\n",
    "        is_subset = all(item in df.columns for item in header);\n",
    "        print(is_subset);\n",
    "       \n",
    "                \n",
    "                       \n",
    "\n",
    "data_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Data_shopee/data_1_1_1.xlsx'\n",
    "destination_path = r\"C:\\Drag_data_in_shopee\\Bot\\Un_process\"  # เปลี่ยนเป็นเส้นทางจริงที่ต้องการย้ายไฟล์ไป\n",
    "shutil.move(path, destination_path);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
